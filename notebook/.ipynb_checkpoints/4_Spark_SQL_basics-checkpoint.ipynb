{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL\n",
    "\n",
    "Spark SQL essentially tries to bridge the gap between the two models we mentioned previously—the relational and procedural models.\n",
    "\n",
    "Spark SQL provides a DataFrame API that can perform relational operations on both external data sources and Spark's built-in distributed collections—at scale!\n",
    "\n",
    "To support a wide variety of diverse data sources and algorithms in Big Data, Spark SQL introduces a novel extensible optimizer called Catalyst, which makes it easy to add data sources, optimization rules, and data types for advanced analytics such as machine learning. Essentially, Spark SQL leverages the power of Spark to perform distributed, robust, in-memory computations at massive scale on Big Data.\n",
    "\n",
    "## Read the csv data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[auctionid: bigint, bid: double, bidtime: double, bidder: string, bidderrate: string, openbid: double, price: double, item: string, auction_type: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Basics').getOrCreate()\n",
    "df = spark.read.csv('../data/auction.csv',header=True, inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------+----------+-------+-----+------------------+-------------+\n",
      "| auctionid|  bid| bidtime|      bidder|bidderrate|openbid|price|              item| auction_type|\n",
      "+----------+-----+--------+------------+----------+-------+-----+------------------+-------------+\n",
      "|1638893549|175.0|2.230949|schadenfreud|         0|   99.0|177.5|Cartier wristwatch|3 day auction|\n",
      "|1638893549|100.0|2.600116|       chuik|         0|   99.0|177.5|Cartier wristwatch|3 day auction|\n",
      "+----------+-----+--------+------------+----------+-------+-----+------------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- auctionid: long (nullable = true)\n",
      " |-- bid: double (nullable = true)\n",
      " |-- bidtime: double (nullable = true)\n",
      " |-- bidder: string (nullable = true)\n",
      " |-- bidderrate: string (nullable = true)\n",
      " |-- openbid: double (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- item: string (nullable = true)\n",
      " |-- auction_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auctionid',\n",
       " 'bid',\n",
       " 'bidtime',\n",
       " 'bidder',\n",
       " 'bidderrate',\n",
       " 'openbid',\n",
       " 'price',\n",
       " 'item',\n",
       " 'auction_type']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|             10681|\n",
      "|   mean|335.04358861528874|\n",
      "| stddev| 433.5660087308641|\n",
      "|    min|              26.0|\n",
      "|    max|            5400.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().select(\"summary\",\"price\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|             10681|\n",
      "|   mean|335.04358861528874|\n",
      "| stddev| 433.5660087308641|\n",
      "|    min|              26.0|\n",
      "|    25%|            186.51|\n",
      "|    50%|            228.01|\n",
      "|    75%|             255.0|\n",
      "|    max|            5400.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().select(\"summary\",\"price\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "| auctionid|      bidder|\n",
      "+----------+------------+\n",
      "|1638893549|schadenfreud|\n",
      "|1638893549|       chuik|\n",
      "+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, IntegerType, StringType, StructType\n",
    "address_schema = [StructField('city',StringType(),True),StructField('state',StringType(),True)]\n",
    "final_add_schema = StructType(fields=address_schema)\n",
    "data_schema = [StructField('id',IntegerType(),True),StructField('name',StringType(),True),final_add_schema]\n",
    "final_struc = StructType(fields=data_schema)\n",
    "df = spark1.read.json('../data/data.json',schema=final_struc)\n",
    "df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
